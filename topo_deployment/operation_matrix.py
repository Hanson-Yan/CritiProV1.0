import numpy as np
from scipy.optimize import minimize

class OperationMatirxSolver:
    def __init__(self, gamma=0.1, eta=10, alpha=0.01, max_iter=1000, tol=1e-5):
        """
        åˆå§‹åŒ–å‚æ•°
        :param gamma: ç¨€ç–æ€§æ­£åˆ™åŒ–å‚æ•°
        :param eta: ç½šå‡½æ•°æƒ©ç½šå› å­
        :param alpha: è¿‘ç«¯æ¢¯åº¦æ³•å­¦ä¹ ç‡
        :param max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•°
        :param tol: æ”¶æ•›é˜ˆå€¼
        """
        self.gamma = gamma
        self.eta = eta
        self.alpha = alpha
        self.max_iter = max_iter
        self.tol = tol
        self.operation_matrix_path="/home/retr0/Project/TopologyObfu/CritiPro/output_file/operation_matrix.txt"
        self.deployment_vector_path="/home/retr0/Project/TopologyObfu/CritiPro/output_file/deployment_vector.txt"

    @staticmethod
    def read_matrix(file_path):
        """
        è¯»å–çŸ©é˜µï¼ˆM æˆ– Fï¼‰ï¼Œæ–‡ä»¶æ¯è¡Œæ˜¯çŸ©é˜µçš„ä¸€è¡Œï¼Œå…ƒç´ ç”¨ç©ºæ ¼åˆ†éš”
        :param file_path: txt æ–‡ä»¶è·¯å¾„
        :return: numpy çŸ©é˜µ
        """
        return np.loadtxt(file_path, dtype=float)

    @staticmethod
    def read_vector(file_path):
        """
        è¯»å–å»¶è¿Ÿå‘é‡ rï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªå…ƒç´ 
        :param file_path: txt æ–‡ä»¶è·¯å¾„
        :return: numpy åˆ—å‘é‡
        """
        return np.loadtxt(file_path, dtype=float).reshape(-1, 1)

    def penalty_function(self, P, M, F, r, delta_max):
        """
        è®¡ç®—ä¼˜åŒ–ç›®æ ‡ H(F) = ||PM - F||_2 + Î³||Pr - r||_1 + Î·Q(P)
        """
        PM = P @ M
        Pr = P @ r
        term1 = np.linalg.norm(PM - F, ord=2)  # ||PM - F||_2
        term2 = self.gamma * np.linalg.norm(Pr - r, ord=1)  # Î³||Pr - r||_1

        # è®¡ç®—ç½šå‡½æ•°é¡¹
        delta = Pr - r
        term3 = np.sum(np.maximum(0, delta - delta_max) ** 2) + np.sum(np.maximum(0, -delta) ** 2)

        return term1 + term2 + self.eta * term3

    def optimize_P(self, M, F, r, delta_max=0.5):
        """
        ä½¿ç”¨ scipy.optimize è¿›è¡Œä¼˜åŒ–æ±‚è§£
        """
        n = M.shape[0]
        P_init = np.eye(n)  # ä»¥å•ä½çŸ©é˜µä¸ºåˆå§‹ P
        bounds = [(0, 1) for _ in range(n * n)]  # çº¦æŸ P åœ¨ [0,1] ä¹‹é—´

        result = minimize(
            lambda P: self.penalty_function(P.reshape(n, n), M, F, r, delta_max)
                    + 0.05 * np.linalg.norm(P.reshape(n, n) - P_init, ord='fro'),  # ğŸ”¥ å¢åŠ çº¦æŸ
            P_init.flatten(), method='L-BFGS-B', bounds=bounds
        )

        return result.x.reshape(n, n)

    @staticmethod
    def soft_thresholding(x, threshold):
        """
        è½¯é˜ˆå€¼æ“ä½œ: prox_{\gamma ||Â·||_1}(x)
        """
        return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)


    def proximal_gradient_method(self, M, F, r, delta_max=100):
        """
        è¿‘ç«¯æ¢¯åº¦æ³•æ±‚è§£ Pï¼Œæ”¯æŒå®Œå…¨è‡ªé€‚åº”å‚æ•°è°ƒæ•´ï¼Œå¹¶å¢åŠ ç¨€ç–æ€§æ§åˆ¶
        """
        n = M.shape[0]
        P = np.random.rand(n, n)  # é‡‡ç”¨éšæœºåˆå§‹åŒ– Pï¼Œè®© P æ›´è‡ªç„¶
        alpha = 0.01  #  é€‚å½“å¢åŠ  alpha è®©ä¼˜åŒ–æ­¥é•¿æ›´å¤§
        gamma = 0.01  # é€‚å½“å‡å°‘ gamma è®© P ä¸è‡³äºå…¨ 0
        eta = 0.5  # é€‚å½“å¢åŠ  eta è®© P ä¸ä¼šé™·å…¥å±€éƒ¨æå°å€¼
        prev_grad = None  # è®°å½•å‰ä¸€æ¬¡æ¢¯åº¦å˜åŒ–

        # r = r / np.max(np.abs(r))  # å½’ä¸€åŒ– rï¼Œé¿å…æ•°å€¼ä¸ç¨³å®š

        for iteration in range(self.max_iter):
            PM = P @ M
            Pr = P @ r

            # è®¡ç®—æ¢¯åº¦
            grad_P = 2 * (PM - F) @ M.T + gamma * np.sign(Pr - r) @ r.T

            # è®¡ç®—ç½šå‡½æ•°æ¢¯åº¦é¡¹
            # delta = Pr - r
            # penalty_grad = 2 * np.maximum(0, delta - delta_max) + 2 * np.maximum(0, -delta)
            # grad_P += eta * penalty_grad
            # ä¿®æ­£åçš„ç½šå‡½æ•°æ¢¯åº¦è®¡ç®—
            delta = Pr - r
            # è®¡ç®—æ¡ä»¶é¡¹
            condition = np.zeros_like(delta)
            condition[delta > delta_max] = delta[delta > delta_max] - delta_max
            condition[delta < 0] = -delta[delta < 0]
            # è®¡ç®—æ¢¯åº¦é¡¹
            penalty_grad = 2 * self.eta * (condition @ r.T)  # (n,n)
            grad_P += penalty_grad

            max_grad = np.max(np.abs(grad_P))
            print(f"Iter {iteration}: max_grad={max_grad}, alpha={alpha}, eta={eta}")

            # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
            if prev_grad is not None:
                if max_grad > prev_grad * 1.2:  # æ¢¯åº¦çªç„¶å˜å¤§ï¼Œé™ä½å­¦ä¹ ç‡
                    alpha = max(alpha * 0.9, 0.005)
                elif max_grad < prev_grad * 0.8:  # æ¢¯åº¦ä¸‹é™å¤ªæ…¢ï¼Œå¢åŠ å­¦ä¹ ç‡
                    alpha = min(alpha * 1.1, 0.1)
            
            prev_grad = max_grad

            # æ¢¯åº¦ä¸‹é™æ›´æ–°
            P_new = P - alpha * grad_P

            # å¼•å…¥ `soft_thresholding` è®© P ä¿æŒç¨€ç–
            # P_new = self.soft_thresholding(P_new, gamma)

            # çº¦æŸ P åœ¨ [0,1] ä¹‹é—´
            P_new = np.clip(P_new, 0, 1)

            # ç›‘æµ‹ P æ˜¯å¦è¿‡ç¨€ç–æˆ–æ¥è¿‘å•ä½çŸ©é˜µ
            if np.all(P_new < 1e-3):  
                eta = max(eta * 0.9, 0.05)  # P å˜å…¨ 0ï¼Œåˆ™å‡å°‘ eta
            elif np.allclose(P_new, np.eye(n), atol=0.1):
                eta = min(eta * 1.1, 5)  # P æ¥è¿‘å•ä½çŸ©é˜µï¼Œåˆ™å¢å¤§ eta

            # æ£€æŸ¥æ”¶æ•›
            if np.linalg.norm(P_new - P) < self.tol:
                print(f" è¿­ä»£ {iteration} æ¬¡åæ”¶æ•›ï¼")
                break

            P = P_new

        np.savetxt(self.operation_matrix_path, P, fmt="%.6f")
        print(f"ç”Ÿæˆçš„æ“ä½œçŸ©é˜µå·²ä¿å­˜è‡³\n{self.operation_matrix_path}")
        np.savetxt(self.deployment_vector_path, Pr, fmt="%.6f")
        print(f"ç”Ÿæˆçš„éƒ¨ç½²å‘é‡å·²ä¿å­˜è‡³\n{self.deployment_vector_path}")
        return P,Pr
    
    def solve(self, M_file, F_file, r_file, method="proximal", delta_max=0.5):
        """
        è¯»å–æ•°æ®å¹¶æ±‚è§£ P
        :param M_file: è·¯ç”±çŸ©é˜µ txt æ–‡ä»¶è·¯å¾„
        :param F_file: æ··æ·†çŸ©é˜µ txt æ–‡ä»¶è·¯å¾„
        :param r_file: å»¶è¿Ÿå‘é‡ txt æ–‡ä»¶è·¯å¾„
        :param method: é€‰æ‹©ä¼˜åŒ–æ–¹æ³• ("proximal" æˆ– "scipy")
        :param delta_max: æœ€å¤§å»¶è¿Ÿçº¦æŸ
        :return: æ±‚è§£å‡ºçš„ P çŸ©é˜µ
        """
        M = self.read_matrix(M_file)
        F = self.read_matrix(F_file)
        r = self.read_vector(r_file)
        
        if method == "scipy":
            P = self.optimize_P(M, F, r, delta_max)
            return P,None
        elif method == "proximal":
            P, Pr= self.proximal_gradient_method(M, F, r, delta_max)
            return P,Pr
        else:
            return None
